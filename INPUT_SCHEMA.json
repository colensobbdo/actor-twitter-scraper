{
    "title": "Twitter scraper",
    "type": "object",
    "schemaVersion": 1,
    "properties": {
        "trendKey": {
            "title": "Trend Key",
            "type": "string",
            "description": "Trend key",
            "editor": "textfield"
        },
        "languageCode": {
            "title": "Language code",
            "type": "string",
            "description": "Just enter the 2-char language code (i.e. en)",
            "editor": "textfield"
        },
        "countryCode": {
            "title": "Country code",
            "type": "string",
            "description": "Just enter the 2-char country code (i.e. nz)",
            "editor": "textfield"
        },
        "ignoreCountryCode": {
            "title": "Ignore country code",
            "type": "boolean",
            "description": "You can decide to not use country code when running search on twitter (a global search will occour instead)",
            "default": false
        },
        "hashtag": {
            "title": "Search terms",
            "type": "string",
            "editor": "textfield",
            "description": "Search for an specific terms and extract tweets for that term."
        },
        "searchMode": {
            "title": "Do you want to filter by content?",
            "description": "This setting will change how the data is received by the scraper.",
            "editor": "select",
            "type": "string",
            "prefill": "",
            "default": "",
            "enum": ["", "live", "user", "image", "video"],
            "enumTitles": ["Top", "Latest", "People", "Photos", "Videos"]
        },
        "mode": {
            "title": "Do you want to scrape replies in addition to tweets?",
            "description": "You can choose to only scrape a user's own tweets or you can choose to also scrape the user's own tweets and the user's replies to other users.",
            "type": "string",
            "editor": "select",
            "default": "replies",
            "prefill": "replies",
            "enumTitles": ["Tweets only", "Tweets and replies to other users"],
            "enum": ["own", "replies"]
        },
        "tweetsDesired": {
            "title": "Set the maximum number of tweets",
            "type": "integer",
            "description": "This value lets you set the maximum number of tweets to retrieve. Twitter has a default limit of around 3,200 tweets. Check the README for workarounds.",
            "maximum": 3300,
            "prefill": 50
        },
        "addUserInfo": {
            "title": "Add user information",
            "description": "Appends an object to each tweet containing the user information. You can decrease the size of your dataset by turning this off.",
            "default": true,
            "type": "boolean",
            "editor": "checkbox"
        },
        "handle": {
            "title": "Do you want to scrape by Twitter handle?",
            "type": "array",
            "description": "You can add the twitter handles of specific profiles you want to scrape. This is a shortcut so that you don't have to add full username URLs like https://twitter.com/username.",
            "editor": "stringList",
            "sectionCaption": "Scrape by Twitter handle or Twitter URL",
            "sectionDescription": "The default option is to scrape using search terms, but you can also scrape by Twitter handles or Twitter URLs."
        },
        "startUrls": {
            "title": "Do you want to scrape by Twitter URL?",
            "description": "This lets you tell the scraper where to start. You can enter Twitter URLs one by one. You can also link to or upload a text file with a list of URLs.",
            "default": [],
            "type": "array",
            "editor": "requestListSources"
        },
        "toDate": {
            "title": "Tweets newer than",
            "description": "Scrape tweets newer than this date. You can use this in conjunction with 'Tweets older than' to create a limited time slice. ",
            "pattern": "(\\d{4}-\\d{2}-\\d{2}|(\\d+)\\s?\\S+)",
            "type": "string",
            "editor": "textfield",
            "sectionCaption": "Do you want to set specific dates?",
            "sectionDescription": "You can choose to scrape only tweets older or newer than a specific date. You can use YYYY-MM-DD format or just relative dates like '1 month' or '2 days'."
        },
        "fromDate": {
            "title": "Tweets older than",
            "description": "Scrape tweets from this date and before. You can use this in conjunction with 'Tweets newer than'to create a limited time slice.",
            "type": "string",
            "pattern": "(\\d{4}-\\d{2}-\\d{2}|(\\d+)\\s?\\S+)",
            "editor": "textfield"
        },
        "proxyConfig": {
            "title": "Proxy configuration",
            "type": "object",
            "description": "This is required if you want to use Apify Proxy.",
            "prefill": {
                "useApifyProxy": true
            },
            "default": {
                "useApifyProxy": true
            },
            "editor": "proxy",
            "sectionCaption": "Proxy configuration",
            "sectionDescription": "Choose which proxies to use."
        },
        "extendOutputFunction": {
            "title": "Extend Output Function",
            "description": "Add or remove properties on the output object or omit the output returning null",
            "type": "string",
            "default": "async ({ data, item, page, request, customData, Apify }) => {\n  return item;\n}",
            "prefill": "async ({ data, item, page, request, customData, Apify }) => {\n  return item;\n}",
            "editor": "javascript",
            "sectionCaption": "Extend scraper functionality",
            "sectionDescription": "You can change the output of the items for your dataset here, or add additional behavior to the scraper."
        },
        "extendScraperFunction": {
            "title": "Extend Scraper Function",
            "description": "Advanced function that allows you to extend the default scraper functionality, allowing you to manually perform actions on the page",
            "type": "string",
            "default": "async ({ page, request, addSearch, addProfile, _, addThread, addEvent, customData, Apify, signal, label }) => {\n \n}",
            "prefill": "async ({ page, request, addSearch, addProfile, _, addThread, addEvent, customData, Apify, signal, label }) => {\n \n}",
            "editor": "javascript"
        },
        "customData": {
            "title": "Custom data",
            "description": "Any data that you want to have available inside the Extend Output/Scraper Function",
            "default": {},
            "prefill": {},
            "type": "object",
            "editor": "json"
        },
        "handlePageTimeoutSecs": {
            "title": "Max timeout seconds",
            "description": "Max timeout for the handlePageFunction. Can be increased for long running processes",
            "default": 5000,
            "prefill": 5000,
            "editor": "number",
            "type": "integer"
        },
        "maxRequestRetries": {
            "title": "Max request retries",
            "description": "Set the max request retries",
            "default": 3,
            "prefill": 3,
            "type": "integer",
            "editor": "number"
        },
        "maxIdleTimeoutSecs": {
            "title": "Scrolling idle seconds",
            "description": "Configures how many seconds of no data received will be considered done",
            "default": 30,
            "prefill": 30,
            "type": "integer",
            "editor": "number"
        },
        "debug": {
            "title": "Debug log",
            "description": "Enable debug log",
            "default": false,
            "type": "boolean",
            "editor": "checkbox"
        },
        "initialCookies": {
            "title": "Login cookies",
            "type": "array",
            "default": [],
            "prefill": [],
            "description": "Your login cookies will be used to bypass the login wall. Check the README for detailed instructions.",
            "editor": "json",
            "sectionCaption": "Login (optional)",
            "sectionDescription": "You can use cookies to have access to more data. Twitter may block your account as a bot though, we recommend using an account you wouldn't mind getting blocked."
        }
    },
    "required": [
        "countryCode",
        "languageCode",
        "trendKey",
        "hashtag",
        "proxyConfig"
    ]
}
